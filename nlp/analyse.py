from __future__ import annotations
import os
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

# One shared client for all requests
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

SYSTEM_SYMPTOM = "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø·Ø¨ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù„ØºØ©. Ø§Ø³ØªØ®Ø±Ø¬ ÙƒÙ„Ù…Ø§Øª Ù…ÙØªØ§Ø­ÙŠØ© Ù„Ù„Ø£Ø¹Ø±Ø§Ø¶ ÙÙ‚Ø·. Ù„Ø§ ØªØ¶Ù Ø´Ø±Ø­Ø§Ù‹."  # noqa: E501
SYSTEM_DIAGNOSIS = (
    "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø·Ø¨ÙŠ Ø®Ø¨ÙŠØ± ÙÙŠ Ø§Ù„ØªØ´Ø®ÙŠØµ. Ø§Ù‚ØªØ±Ø­ ØªØ´Ø®ÙŠØµØ§Øª Ù…Ø­ØªÙ…Ù„Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ."  # noqa: E501
)


# -----------------------------------------------------------------------------
# ğŸ”‘  Public functions
# -----------------------------------------------------------------------------


def extract_symptom_keywords(summary: str, transcript: str) -> str:
    """Return Arabic symptom keywords found in summary + transcript."""

    prompt = f"""
    Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„Ø£Ø¹Ø±Ø§Ø¶ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠØŒ Ù…ÙØµÙˆÙ„Ø© Ø¨ÙÙˆØ§ØµÙ„:

    Ø§Ù„Ù…Ù„Ø®Øµ:
    {summary}

    Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„:
    {transcript}
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",  # cheaper + fast; change if needed
            messages=[
                {"role": "system", "content": SYSTEM_SYMPTOM},
                {"role": "user", "content": prompt},
            ],
            max_tokens=128,
            temperature=0.2,
        )
        return response.choices[0].message.content.strip()
    except Exception as exc:  # pragma: no cover â€“ surfaced to UI
        raise RuntimeError(f"Symptom keyword extraction failed: {exc}") from exc


def extract_possible_diagnoses(summary: str, transcript: str) -> str:
    """Return possible diagnoses mentioned or implied in the text."""

    prompt = f"""
    Ø§Ø³ØªÙ†Ø§Ø¯Ø§Ù‹ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù„Ø®Øµ ÙˆØ§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„ØŒ Ø­Ø¯Ø¯ Ø£ÙŠ ØªØ´Ø®ÙŠØµØ§Øª Ù…Ø­ØªÙ…Ù„Ø© ØªÙ… Ø°ÙƒØ±Ù‡Ø§ Ø£Ùˆ Ø§Ù„Ø¥Ø´Ø§Ø±Ø© Ø¥Ù„ÙŠÙ‡Ø§. Ù‚Ø§Ø¨Ù„Ù‡Ø§ ÙÙŠ Ù†Ù‚Ø§Ø· Ù…Ø®ØªØµØ±Ø©:

    Ø§Ù„Ù…Ù„Ø®Øµ:
    {summary}

    Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„:
    {transcript}
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": SYSTEM_DIAGNOSIS},
                {"role": "user", "content": prompt},
            ],
            max_tokens=160,
            temperature=0.3,
        )
        return response.choices[0].message.content.strip()
    except Exception as exc:  # pragma: no cover
        raise RuntimeError(f"Diagnosis extraction failed: {exc}") from exc
